{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEATHER CHAT BOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from itertools import chain\n",
    "from nltk import NaiveBayesClassifier as nbc\n",
    "import codecs\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import datefinder\n",
    "import time\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "import pywapi\n",
    "import random\n",
    "import string\n",
    "import parsedatetime as pdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Default Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_default_location():\n",
    "\n",
    "    reader = codecs.getreader(\"utf-8\")\n",
    "    url = 'http://ipinfo.io/json'\n",
    "    response = urlopen(url)\n",
    "    data = json.load(reader(response))\n",
    "    city = data['city']\n",
    "    region=data['region']\n",
    "    if_location_not_given = city + \", \" + region\n",
    "    return if_location_not_given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nuzvid, Andhra Pradesh'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_default_location()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_day_of_week(question):\n",
    "\n",
    "    cal = pdt.Calendar()\n",
    "    now = datetime.datetime.now()\n",
    "    \n",
    "    question_time  = cal.parseDT(question, now)[0]\n",
    "    \n",
    "#     print(question_time)\n",
    "    question = question.lower()\n",
    "    matches = list(datefinder.find_dates(question))\n",
    "\n",
    "    if len(matches) > 0:\n",
    "        date = matches[0]\n",
    "        day = date.strftime('%A')\n",
    "    else:\n",
    "        if 'today' in question:\n",
    "            day = ((datetime.date.today()).strftime('%A'))\n",
    "        elif 'day after tomorrow' in question:\n",
    "            day = ((datetime.date.today() + datetime.timedelta(days = 2)).strftime('%A'))\n",
    "        elif 'tomorrow' in question:\n",
    "            day = ((datetime.date.today() + datetime.timedelta(days = 1)).strftime('%A'))\n",
    "        else:\n",
    "            day = ((datetime.date.today()).strftime('%A'))\n",
    "    return day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_model_filename = r'C:\\Users\\Banu Prakash\\Desktop\\stanford-ner\\classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "_path_to_jar = r'C:\\Users\\Banu Prakash\\Desktop\\stanford-ner\\stanford-ner.jar'\n",
    "# Then we initialize the NLTK's Stanford NER Tagger API with the DIRECT PATH to the model and .jar file.\n",
    "st = StanfordNERTagger(model_filename=_model_filename, path_to_jar=_path_to_jar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_location(question):\n",
    "      \n",
    "    _model_filename = r'C:\\Users\\Banu Prakash\\Desktop\\stanford-ner\\classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "    _path_to_jar = r'C:\\Users\\Banu Prakash\\Desktop\\stanford-ner\\stanford-ner.jar'\n",
    "# Then we initialize the NLTK's Stanford NER Tagger API with the DIRECT PATH to the model and .jar file.\n",
    "    location_tagger = StanfordNERTagger(model_filename=_model_filename, path_to_jar=_path_to_jar)\n",
    "#     location_tagger = StanfordNERTagger('Tagger/stanford-ner/classifiers/ner-eng-ie.crf-3-all2008-distsim.ser.gz', 'Tagger/stanford-ner/stanford-ner.jar')\n",
    "    question = question.title()\n",
    "    tag = location_tagger.tag(question.split())\n",
    "    loc_word = ''\n",
    "    for word,tag in tag:\n",
    "        if(tag == 'LOCATION'):\n",
    "            loc_word = loc_word + \" \" + word\n",
    "        loc_word = loc_word.strip()\n",
    "    if loc_word == '':\n",
    "        loc_word = get_default_location()\n",
    "    return loc_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bangalore'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_location(\"bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_location(question):\n",
    "    \n",
    "#     location_tagger = StanfordNERTagger('Tagger/stanford-ner/classifiers/ner-eng-ie.crf-3-all2008-distsim.ser.gz', 'Tagger/stanford-ner/stanford-ner.jar')\n",
    "#     question = question.title()\n",
    "#     tag = location_tagger.tag(question.split())\n",
    "#     loc_word = ''\n",
    "#     for word,tag in tag:\n",
    "#         if(tag == 'LOCATION'):\n",
    "#             loc_word = loc_word + \" \" + word\n",
    "#         loc_word = loc_word.strip()\n",
    "#     if loc_word == '':\n",
    "#         loc_word = get_default_location()\n",
    "#     return loc_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bangalore'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_location(\"bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from nltk.tag.stanford import StanfordNERTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# st = StanfordNERTagger('/usr/share/stanford-ner/classifiers/all.3class.distsim.crf.ser.gz',\n",
    "#                '/usr/share/stanford-ner/stanford-ner.jar') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# import zipfile\n",
    "\n",
    "# # First we retrieve the model file from the website.\n",
    "# urllib.request.urlretrieve(r'http://www.maltparser.org/mco/english_parser/engmalt.poly-1.7.mco', r'C:\\Users\\Banu Prakash\\Desktop\\engmalt.poly-1.7.mco')\n",
    "\n",
    "# # Then we retrieve the parser zip file from the website.\n",
    "# urllib.request.urlretrieve(r'http://maltparser.org/dist/maltparser-1.8.1.zip', r'C:\\Users\\Banu Prakash\\Desktop\\maltparser-1.8.1.zip')\n",
    "\n",
    "# # Then we create a Pythonic zipfile object by initializing it with the full path to the zipfile.\n",
    "# zfile = zipfile.ZipFile(r'C:\\Users\\Banu Prakash\\Desktop\\maltparser-1.8.1.zip')\n",
    "# # And asks python to extact the file to the directory: C:\\Users\\Thu\\Desktop\\maltparser-1.8.1\n",
    "# zfile.extractall(r'C:\\Users\\Banu Prakash\\Desktop\\maltparser-1.8.1')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from nltk.parse import malt\n",
    "# # We initialize the MaltParser API with the DIRECT PATH to the malt parser DIRECTORY (not the jar file) and the .mco file.\n",
    "# mp = malt.MaltParser(r'C:\\Users\\Banu Prakash\\Desktop\\maltparser-1.8.1',  r'C:\\Users\\Banu Prakash\\Desktop\\engmalt.poly-1.7.mco')\n",
    "# mp.parse_one('I shot an elephant in my pajamas .'.split()).tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# import zipfile\n",
    "# urllib.request.urlretrieve(r'http://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip', r'C:\\Users\\Banu Prakash\\Desktop\\stanford-ner-2015-04-20.zip')\n",
    "# zfile = zipfile.ZipFile(r'C:\\Users\\Banu Prakash\\Desktop\\stanford-ner-2015-04-20.zip')\n",
    "# zfile.extractall(r'C:\\Users\\Banu Prakash\\Desktop\\stanford-ner')\n",
    "\n",
    "# from nltk.tag.stanford import StanfordNERTagger\n",
    "# # First we set the direct path to the NER Tagger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# _model_filename = r'C:\\Users\\Banu Prakash\\Desktop\\stanford-ner\\classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "# _path_to_jar = r'C:\\Users\\Banu Prakash\\Desktop\\stanford-ner\\stanford-ner.jar'\n",
    "# # Then we initialize the NLTK's Stanford NER Tagger API with the DIRECT PATH to the model and .jar file.\n",
    "# st = StanfordNERTagger(model_filename=_model_filename, path_to_jar=_path_to_jar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tagger =  ner.HttpNER(host='localhost', port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tagger.get_entities(\"University of California is located in California, United States\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get weather of that Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weather(city, day_of_week):\n",
    "   \n",
    "\n",
    " # Get Weather.com Data\n",
    "    count = 0\n",
    "    lookup = pywapi.get_location_ids(city)\n",
    "    while len(lookup) != 1:\n",
    "        if len(lookup) > 1:\n",
    "            print('Choose the correct one: ')\n",
    "            for i,j in zip(lookup.values(),range(1,len(lookup.values())+1)):\n",
    "                print(j,' Which one do you want ?',i)\n",
    "            city = input('Enter Location: ')\n",
    "            lookup = pywapi.get_location_ids(city)\n",
    "        if len(lookup) == 0:\n",
    "            print('Curent Location ',city,' is unable to locate')\n",
    "            city = input('Please provide the location correctly: ')\n",
    "            count += 1\n",
    "            lookup = pywapi.get_location_ids(city)\n",
    "            if count == 2:\n",
    "                city = input('Please provide the best nearest location, we are unable to find that for you : ')\n",
    "                lookup = pywapi.get_location_ids(city)\n",
    "    for k in lookup:\n",
    "        location_id = k\n",
    "    \n",
    "# Extracting the weather forcast for that location \n",
    "\n",
    "    weather_com = pywapi.get_weather_from_weather_com(location_id)\n",
    "    now_temp = weather_com['current_conditions']['temperature']\n",
    "    weather_forecast = pd.DataFrame.from_dict(weather_com['forecasts'])\n",
    "    weather_update = weather_com['current_conditions']['last_updated']\n",
    "    weather_forecast_night_data = pd.DataFrame.from_dict(weather_forecast['night'])\n",
    "    weather_forecast_day_data = pd.DataFrame.from_dict(weather_forecast['day'])\n",
    "    weather_forecast_day_night_data = weather_forecast_day_data.join(weather_forecast_night_data)\n",
    "\n",
    "#Extracting just relevant data\n",
    "\n",
    "    main_list = []\n",
    "    time_list = []\n",
    "    night_day_data = {}\n",
    "    for time in weather_forecast_day_night_data:\n",
    "        for i in range(len(weather_forecast_day_night_data[time])):\n",
    "            for key,value in weather_forecast_day_night_data[time][i].items():\n",
    "                if key == 'chance_precip':\n",
    "                    n_key = time + '_chances_of_rain'\n",
    "                    night_day_data[n_key] = value + '%'\n",
    "                if key == 'text':\n",
    "                    n_key = time + '_weather'\n",
    "                    if value == '':\n",
    "                        value = 'Clear'\n",
    "                    night_day_data[n_key] = value\n",
    "                if key == 'humidity':\n",
    "                    n_key = time + '_humidity'\n",
    "                    night_day_data[n_key] = value\n",
    "            time_list.append(night_day_data)\n",
    "            night_day_data = {}\n",
    "        main_list.append(time_list)\n",
    "        time_list = []\n",
    "\n",
    "# Merging the needful Data\n",
    "\n",
    "    day_data = pd.DataFrame.from_dict(main_list[0])\n",
    "    night_data = pd.DataFrame.from_dict(main_list[1])\n",
    "    day_data = day_data.join(night_data)\n",
    "    weather_forecast['current temperature'] = now_temp\n",
    "    high_data = pd.DataFrame(weather_forecast['high']).join(pd.DataFrame(weather_forecast['low']))\n",
    "    high_data_day = pd.DataFrame(weather_forecast['day_of_week']).join(high_data)\n",
    "    weather = high_data_day.join(day_data)\n",
    "    weather = weather.join(pd.DataFrame(weather_forecast['current temperature']))\n",
    "# Getting for that day\n",
    "\n",
    "    weather = weather.set_index(['day_of_week'])\n",
    "    if day_of_week in weather.index.tolist():\n",
    "        final_data = pd.DataFrame(weather.loc[day_of_week])\n",
    "        return final_data,weather_update,city\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_traindata():\n",
    "    train_csv = pd.read_csv('weathertrain.csv',header= None,names = ['sentence','label'])\n",
    "    subset = train_csv[['sentence', 'label']]\n",
    "    tuples = [tuple(x) for x in subset.values]\n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNBC():\n",
    "    data = get_traindata()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    d1 = [(' '.join(list((i for i in word_tokenize(sentence) if i not in stop_words))),tag) for sentence, tag in data ]\n",
    "    vocabulary = set(chain(*[word_tokenize(i[0].lower()) for i in d1 if i not in stop_words]))\n",
    "    feature_set = [({i:(i in word_tokenize(sentence.lower())) for i in vocabulary},tag) for sentence, tag in d1]\n",
    "    classifier = nbc.train(feature_set)\n",
    "    return vocabulary,classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier for getting class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class(query):\n",
    "    test_sentence = query\n",
    "    vocabulary,classifier = trainNBC()\n",
    "    featurized_test_sentence =  {i:(i in word_tokenize(test_sentence.lower())) for i in vocabulary}\n",
    "    ans = classifier.classify(featurized_test_sentence)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method to get Class Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_output(query):\n",
    "    temperature = {}\n",
    "    weather_text = {}\n",
    "    rain_data = {}\n",
    "    full_details = {}\n",
    "    temperature['Highest temperature'] = weather.loc['high'][day_of_week]\n",
    "    temperature['Lowest temperature'] = weather.loc['low'][day_of_week]\n",
    "    temperature['Current temperature'] = weather.loc['current temperature'][day_of_week]\n",
    "    weather_text['During Day'] = weather.loc['day_weather'][day_of_week]\n",
    "    weather_text['During Night'] = weather.loc['night_weather'][day_of_week]\n",
    "    rain_data['During Day'] = weather.loc['day_chances_of_rain'][day_of_week]\n",
    "    rain_data['During Night'] = weather.loc['night_chances_of_rain'][day_of_week]\n",
    "    full_details['Day Time'] = [weather.loc['day_weather'][day_of_week],weather.loc['day_chances_of_rain'][day_of_week],weather.loc['day_humidity'][day_of_week]]\n",
    "    full_details['Night Time'] = [weather.loc['night_weather'][day_of_week],weather.loc['night_chances_of_rain'][day_of_week],weather.loc['night_humidity'][day_of_week]]\n",
    "    temp_pd = pd.DataFrame.from_dict(temperature,orient='index')\n",
    "    rain_pd = pd.DataFrame.from_dict(rain_data,orient='index')\n",
    "    weather_pd = pd.DataFrame.from_dict(weather_text,orient='index')\n",
    "    full_details_pd = pd.DataFrame.from_dict(full_details,orient='index')\n",
    "    temp_pd.columns = ['temperature']\n",
    "    temp = pd.DataFrame(temp_pd)\n",
    "    rain_pd.columns = ['rain']\n",
    "    weather_pd.columns = ['weather']\n",
    "    full_details_pd.columns = ['Weather','Chances of Rain','Humidity']\n",
    "    temp_pd = temp_pd.unstack(level=1)\n",
    "    rain_pd = rain_pd.unstack(level=1)\n",
    "    weather_pd = weather_pd.unstack(level=1)\n",
    "    frames = [temp_pd, rain_pd, weather_pd]\n",
    "    result = pd.DataFrame(pd.concat(frames))\n",
    "    result.columns = ['Details'] \n",
    "    category = get_class(query)\n",
    "    print(temp)\n",
    "    if category == 'max':\n",
    "        output = temp.loc['Highest temperature']['temperature']\n",
    "    elif category == 'min':\n",
    "        output = temp.loc['Lowest temperature']['temperature']\n",
    "    elif category == 'temperature':\n",
    "        output = temp.loc['Current temperature']['temperature']\n",
    "    else:\n",
    "        output = result.loc[category]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Check for greetings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GREETING_KEYWORDS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",)\n",
    "\n",
    "GREETING_RESPONSES = [\"'sup bro\", \"hey\", \"*nods*\", \"hey you get my snap?\"]\n",
    "\n",
    "def check_for_greeting(sentence):\n",
    "    \"\"\"If any of the words in the user's input was a greeting, return a greeting response\"\"\"\n",
    "    for word in word_tokenize(sentence):\n",
    "        if word.lower() in GREETING_KEYWORDS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "        else:\n",
    "            return \"Nothing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get User Input and produce output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! What do you want to know ? Hi\n",
      "'sup bro How May I assist you ?How's weather in Chirala ?\n",
      "Choose the correct one: \n",
      "1  Which one do you want ? Chirala, AP, India\n",
      "2  Which one do you want ? Chirala, 5, Bangladesh\n",
      "3  Which one do you want ? Chirala, JK, Pakistan\n",
      "Enter Location: Chirala, AP, India\n",
      "                    temperature\n",
      "Highest temperature          27\n",
      "Lowest temperature           26\n",
      "Current temperature          27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>During Day</th>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>During Night</th>\n",
       "      <td>Mostly Cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Details\n",
       "During Day            Clear\n",
       "During Night  Mostly Cloudy"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = input('Hello! What do you want to know ? ')\n",
    "greet = check_for_greeting(query)\n",
    "while greet != 'Nothing':\n",
    "    new_query = greet + ' How May I assist you ?'\n",
    "    query = input(new_query)\n",
    "    greet = check_for_greeting(query)\n",
    "question = \"\".join(l for l in query if l not in string.punctuation)\n",
    "city = get_location(question)\n",
    "day_of_week = get_day_of_week(question)\n",
    "weather, time, city = get_weather(city,day_of_week)\n",
    "if city == None:\n",
    "    print('Cannnot predict for data more than 5 days')\n",
    "else:   \n",
    "    output = get_output(query)\n",
    "    #print(\"**** \",output.columns.tolist()[0].capitalize(),\" Details for \",city,\" on \",day_of_week,\" as updated on \",time,\" ****\")\n",
    "    weather_data = output\n",
    "weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('INXX0012', 'Bangalore, KA, India')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = 'Bangalore'\n",
    "pywapi.get_loc_id_from_weather_com(location)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units': {'temperature': 'C', 'distance': 'km', 'speed': 'km/h', 'pressure': 'mb', 'rainfall': 'mm'}, 'location': {'name': 'New York, NY (10001)', 'lat': '40.75', 'lon': '-74.00'}, 'current_conditions': {'last_updated': '10/19/17 2:51 AM EDT', 'station': 'Nyc/Central Park, NY, US', 'temperature': '15', 'feels_like': '15', 'text': 'Fair', 'icon': '33', 'humidity': '57', 'visibility': '16.1', 'dewpoint': '7', 'barometer': {'reading': '1019.98', 'direction': ''}, 'wind': {'speed': '9', 'gust': 'N/A', 'direction': '280', 'text': 'W'}, 'uv': {'index': '0', 'text': 'Low'}, 'moon_phase': {'icon': '28', 'text': 'Waning Crescent'}}, 'forecasts': [{'day_of_week': 'Thursday', 'date': 'Oct 19', 'high': '21', 'low': '12', 'sunrise': '7:12 AM', 'sunset': '6:09 PM', 'day': {'icon': '32', 'text': 'Sunny', 'brief_text': 'Sunny', 'chance_precip': '0', 'humidity': '56', 'wind': {'speed': '11', 'gust': 'N/A', 'direction': '222', 'text': 'SW'}}, 'night': {'icon': '31', 'text': 'Clear', 'brief_text': 'Clear', 'chance_precip': '0', 'humidity': '59', 'wind': {'speed': '11', 'gust': 'N/A', 'direction': '222', 'text': 'SW'}}}, {'day_of_week': 'Friday', 'date': 'Oct 20', 'high': '21', 'low': '11', 'sunrise': '7:12 AM', 'sunset': '6:09 PM', 'day': {'icon': '32', 'text': 'Sunny', 'brief_text': 'Sunny', 'chance_precip': '0', 'humidity': '46', 'wind': {'speed': '9', 'gust': 'N/A', 'direction': '312', 'text': 'NW'}}, 'night': {'icon': '31', 'text': 'Clear', 'brief_text': 'Clear', 'chance_precip': '0', 'humidity': '52', 'wind': {'speed': '9', 'gust': 'N/A', 'direction': '312', 'text': 'NW'}}}, {'day_of_week': 'Saturday', 'date': 'Oct 21', 'high': '22', 'low': '13', 'sunrise': '7:12 AM', 'sunset': '6:09 PM', 'day': {'icon': '32', 'text': 'Sunny', 'brief_text': 'Sunny', 'chance_precip': '0', 'humidity': '45', 'wind': {'speed': '4', 'gust': 'N/A', 'direction': '262', 'text': 'W'}}, 'night': {'icon': '33', 'text': 'Mostly Clear', 'brief_text': 'M Clear', 'chance_precip': '10', 'humidity': '71', 'wind': {'speed': '4', 'gust': 'N/A', 'direction': '262', 'text': 'W'}}}, {'day_of_week': 'Sunday', 'date': 'Oct 22', 'high': '22', 'low': '15', 'sunrise': '7:12 AM', 'sunset': '6:09 PM', 'day': {'icon': '30', 'text': 'Partly Cloudy', 'brief_text': 'P Cloudy', 'chance_precip': '10', 'humidity': '66', 'wind': {'speed': '8', 'gust': 'N/A', 'direction': '183', 'text': 'S'}}, 'night': {'icon': '29', 'text': 'Partly Cloudy', 'brief_text': 'P Cloudy', 'chance_precip': '10', 'humidity': '80', 'wind': {'speed': '8', 'gust': 'N/A', 'direction': '183', 'text': 'S'}}}, {'day_of_week': 'Monday', 'date': 'Oct 23', 'high': '22', 'low': '17', 'sunrise': '7:12 AM', 'sunset': '6:09 PM', 'day': {'icon': '30', 'text': 'Partly Cloudy', 'brief_text': 'P Cloudy', 'chance_precip': '10', 'humidity': '73', 'wind': {'speed': '11', 'gust': 'N/A', 'direction': '196', 'text': 'SSW'}}, 'night': {'icon': '29', 'text': 'Partly Cloudy', 'brief_text': 'P Cloudy', 'chance_precip': '20', 'humidity': '82', 'wind': {'speed': '11', 'gust': 'N/A', 'direction': '196', 'text': 'SSW'}}}]}\n"
     ]
    }
   ],
   "source": [
    "pywapi.get_weather_from_weather_com('10001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
